from unittest import result
import cv2
from matplotlib import image
import numpy as np
#from paddle import crop
from ultralytics import YOLO
from paddleocr import PaddleOCR
import re

# ========== 1ï¸âƒ£ åŠ è½½æ¨¡å‹ ==========
yolo_model = YOLO('./runs/detect/train/weights/best.pt')  # YOLOæ¨¡å‹è·¯å¾„
#ocr = PaddleOCR(use_textline_orientation=True, lang='ch')  # OCRæ¨¡å‹ï¼ˆå¯è¯†åˆ« Î¼mï¼‰
# å…³é—­æ–¹å‘æ£€æµ‹ï¼Œscale bar ä¸€èˆ¬éƒ½æ˜¯æ°´å¹³çš„ï¼Œä¸éœ€è¦è¿™ä¸ªåŠŸèƒ½
ocr = PaddleOCR(use_angle_cls=False, lang='ch', use_gpu=False,enable_mkldnn=False,show_log=False)
def detect_scale(image_path, conf_thresh=0.3):  # é™ä½ç½®ä¿¡åº¦é˜ˆå€¼æ–¹ä¾¿è°ƒè¯•
    image = cv2.imread(image_path)
    if image is None:
        print(f"å›¾åƒè·¯å¾„é”™è¯¯æˆ–æ— æ³•è¯»å–: {image_path}")
        return None, None, None

    results = yolo_model(image)[0]
    scale_bar_box = None
    scale_text_box = None

    print("\n--- YOLO æ£€æµ‹ç»“æœ ---")
    for box in results.boxes:
        cls_id = int(box.cls[0])
        conf = float(box.conf[0])
        label = results.names[cls_id]
        xyxy = box.xyxy[0].cpu().numpy().astype(int)
        print(f"ç±»åˆ«: {label}, ç½®ä¿¡åº¦: {conf:.2f}, åæ ‡: {xyxy}")
        if conf < conf_thresh:
            continue
        if label.lower() == "scale_bar":
            scale_bar_box = xyxy
        elif label.lower() == "scale_text":
            scale_text_box = xyxy

    return image, scale_bar_box, scale_text_box
# ========== 3ï¸âƒ£ OCRè¯†åˆ«æ¯”ä¾‹å°ºæ–‡å­— (ä¿®æ­£ç‰ˆ) ==========
def recognize_scale_text(image, text_box):
    if text_box is None:
        print("scale_text_box ä¸º Noneï¼Œæ— æ³• OCR")
        return None

    x1, y1, x2, y2 = text_box
    # ç¨å¾®å¤šåˆ‡ä¸€ç‚¹è¾¹ç¼˜ (Padding)ï¼Œé˜²æ­¢å­—è¢«åˆ‡æ–­
    pad = 5
    h, w = image.shape[:2]
    x1 = max(0, x1 - pad)
    y1 = max(0, y1 - pad)
    x2 = min(w, x2 + pad)
    y2 = min(h, y2 + pad)

    # è£å‰ªå›¾åƒ
    crop = image[y1:y2, x1:x2]
    
    # å›¾åƒé¢„å¤„ç†ï¼šæ”¾å¤§2å€ï¼ŒäºŒå€¼åŒ–ï¼Œæé«˜è¯†åˆ«ç‡
    crop = cv2.resize(crop, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)
    gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)
    _, crop_bin = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    crop_bin = cv2.cvtColor(crop_bin, cv2.COLOR_GRAY2BGR)

    # debugging: ä¿å­˜ä¸€ä¸‹è£å‰ªå›¾çœ‹çœ‹å¯¹ä¸å¯¹ï¼ˆå¯é€‰ï¼‰
    # cv2.imwrite("../temp_data/debug_crop.jpg", crop_bin)

    # ğŸ”¥ğŸ”¥ğŸ”¥ æ ¸å¿ƒä¿®æ”¹ç‚¹ ğŸ”¥ğŸ”¥ğŸ”¥
    # det=False: ä¸è¿›è¡Œæ£€æµ‹ï¼ˆå› ä¸ºYOLOå·²ç»æ£€æµ‹è¿‡äº†ï¼‰ï¼Œè·³è¿‡å´©æºƒçš„æ¨¡å—
    # cls=False: ä¸è¿›è¡Œæ–¹å‘åˆ†ç±»
    try:
        result = ocr.ocr(crop_bin, det=False, cls=False)
    except Exception as e:
        print(f"PaddleOCR è¿è¡ŒæŠ¥é”™: {e}")
        return None

    # det=False æ—¶ï¼Œè¿”å›æ ¼å¼ç›´æ¥æ˜¯ [('æ–‡æœ¬', ç½®ä¿¡åº¦), ...]
    if not result:
        print("OCR æœªè¯†åˆ«åˆ°æ–‡å­—")
        return None

    print(f"OCRåŸå§‹ç»“æœ: {result}")
    
    # è§£æç»“æœ (å–ç½®ä¿¡åº¦æœ€é«˜çš„ä¸€æ¡ï¼Œé€šå¸¸åªæœ‰ä¸€æ¡)
    # result ç»“æ„ç±»ä¼¼äº [('500um', 0.99), ('å…¶ä»–', 0.8)...]
    text = ""
    if isinstance(result[0], tuple):
        text, conf = result[0]
    elif isinstance(result[0], list): # é˜²å¾¡æ€§ç¼–ç¨‹
        text, conf = result[0]
    else:
        # æŸäº›ç‰ˆæœ¬å¯èƒ½ç›´æ¥è¿”å›åˆ—è¡¨
        text = str(result[0])
    
    text = text.strip()
    print("æœ€ç»ˆè¯†åˆ«æ–‡å­—:", text)

    # ======== è‡ªåŠ¨ä¿®æ­£è§„åˆ™ ========
    # å¸¸è§è¯¯è¯†åˆ«ä¿®æ­£
    text = text.replace("u", "Î¼").replace("Âµ", "Î¼").replace("rn", "m").replace("wr", "Î¼m").replace("w", "Î¼")
    
    # å¦‚æœç»“æœåªæœ‰æ•°å­— (ä¾‹å¦‚ "200")ï¼Œå¼ºåˆ¶è¡¥ä¸Š "Î¼m"
    if re.fullmatch(r"[\d\.]+", text):
        text += "Î¼m"

    return text
# ========== 3ï¸âƒ£ OCRè¯†åˆ«æ¯”ä¾‹å°ºæ–‡å­— ==========
def _recognize_scale_text(image, text_box):
    if text_box is None:
        print("scale_text_box ä¸º Noneï¼Œæ— æ³• OCR")
        return None

    x1, y1, x2, y2 = text_box
    pad = 8
    x1 = max(0, x1 - pad)
    y1 = max(0, y1 - pad)
    x2 = min(image.shape[1], x2 + pad)
    y2 = min(image.shape[0], y2 + pad)

    crop = image[y1:y2, x1:x2]
    crop = cv2.resize(crop, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)
    gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)
    _, crop_bin = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    crop_bin = cv2.cvtColor(crop_bin, cv2.COLOR_GRAY2BGR)

    result = ocr.ocr(crop_bin)
    if not result or not isinstance(result, list):
        print("OCR æœªè¯†åˆ«åˆ°æ–‡å­—")
        return None

    # ======== PaddleOCR è¾“å‡ºè§£æ ========
    text_candidates = []
    if isinstance(result[0], dict) and 'rec_texts' in result[0]:
        rec_texts = result[0]['rec_texts']
        rec_scores = result[0]['rec_scores']
        text_candidates = list(zip(rec_texts, rec_scores))
    else:
        try:
            for line in result[0]:
                if isinstance(line, list) and len(line) > 1:
                    txt, conf = line[1]
                    text_candidates.append((txt, conf))
        except Exception as e:
            print("æ— æ³•è§£æ OCR ç»“æœç»“æ„:", e)
            print("result =", result)
            return None

    if not text_candidates:
        print("æœªæ£€æµ‹åˆ°æœ‰æ•ˆæ–‡å­—")
        return None

    print(f"OCRè¯†åˆ«ç»“æœ: {text_candidates}")
    best_text, best_conf = sorted(text_candidates, key=lambda x: x[1], reverse=True)[0]
    text = best_text.strip()
    print("æœ€ç»ˆè¯†åˆ«æ–‡å­—:", text)

    # ======== è‡ªåŠ¨ä¿®æ­£è§„åˆ™ ========
    # PaddleOCR å¸¸è§è¯¯è¯†åˆ« Î¼m -> u, rn, wr, w, m
    text = text.replace("u", "Î¼").replace("Âµ", "Î¼").replace("rn", "m").replace("wr", "Î¼m").replace("w", "Î¼")

    # å¦‚æœåªæœ‰æ•°å­—æˆ–ç¼ºå•ä½ï¼Œè‡ªåŠ¨è¡¥ Î¼m
    if re.fullmatch(r"[\d\.]+", text):
        text += "Î¼m"

    print("è§£ææ¯”ä¾‹å°ºåŸå§‹æ–‡å­—:", text)

    # ======== æå–æ•°å€¼å’Œå•ä½ ========
    match = re.search(r"([\d\.]+)\s*([a-zA-ZÎ¼]+)?", text)
    if match:
        value = float(match.group(1))
        unit = match.group(2) if match.group(2) else "Î¼m"  # é»˜è®¤è¡¥ Î¼m
        print(f"è§£æç»“æœ: æ•°å€¼={value}, å•ä½={unit}")
        return value, unit
    else:
        print(f"æ— æ³•è§£ææ–‡å­—ä¸ºæ•°å€¼å•ä½: {text}")
        return None


# ========== 4ï¸âƒ£ è§£ææ•°å€¼å’Œå•ä½ ==========
def parse_scale_text(text):
    print(f"è§£ææ¯”ä¾‹å°ºåŸå§‹æ–‡å­—: {text}")
    if not isinstance(text, str):
        text = str(text)
    match = re.search(r"([\d\.]+)\s*([a-zA-ZÎ¼um]+)?", text)
    if match:
        value = float(match.group(1))
        unit = match.group(2).replace("u", "Î¼").replace("Âµ", "Î¼") if match.group(2) else ""
        print(f"è§£æç»“æœ: æ•°å€¼={value}, å•ä½={unit}")
        return value, unit
    else:
        print(f"æ— æ³•è§£ææ–‡å­—ä¸ºæ•°å€¼å•ä½: {text}")
        return None, None

# ========== 5ï¸âƒ£ è®¡ç®—æ¯”ä¾‹ï¼ˆÎ¼m/pixelï¼‰ ==========
def compute_scale_ratio(scale_bar_box, scale_value):
    if scale_bar_box is None or scale_value is None:
        return None
    x1, y1, x2, y2 = scale_bar_box
    pixel_length = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)
    ratio = scale_value / pixel_length
    return ratio, pixel_length

# ========== 6ï¸âƒ£ ä¸»æµç¨‹ ==========
def process_image(image_path):
    image, scale_bar_box, scale_text_box = detect_scale(image_path)
    if image is None:
        return

    print("æ£€æµ‹åˆ°çš„scale_bar_box:", scale_bar_box)
    print("æ£€æµ‹åˆ°çš„scale_text_box:", scale_text_box)

    text = recognize_scale_text(image, scale_text_box)
    if text is None:
        print("æœªè¯†åˆ«åˆ°æ¯”ä¾‹å°ºæ–‡å­—")
        return

    scale_value, unit = parse_scale_text(text)
    if scale_value is None:
        return

    ratio, pixel_length = compute_scale_ratio(scale_bar_box, scale_value)
    if ratio is None:
        print("æœªæ£€æµ‹åˆ°æ¯”ä¾‹å°ºæ¡")
        return

    print(f"\n=== æœ€ç»ˆç»“æœ ===")
    print(f"è¯†åˆ«ç»“æœ: {scale_value} {unit}")
    print(f"æ¯”ä¾‹å°ºé•¿åº¦: {pixel_length:.2f} pixels")
    print(f"åƒç´ æ¯”ä¾‹: {ratio:.4f} {unit}/pixel")

    # å¯è§†åŒ–æ£€æµ‹ç»“æœ
    if scale_bar_box is not None:
        cv2.rectangle(image, (scale_bar_box[0], scale_bar_box[1]),
                             (scale_bar_box[2], scale_bar_box[3]), (0,255,0), 2)
        cv2.putText(image, "Scale Bar", (scale_bar_box[0], scale_bar_box[1]-5),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 2)
    if scale_text_box is not None:
        cv2.rectangle(image, (scale_text_box[0], scale_text_box[1]),
                             (scale_text_box[2], scale_text_box[3]), (255,0,0), 2)
        cv2.putText(image, str(text), (scale_text_box[0], scale_text_box[1]-5),
            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)


    cv2.imwrite("../temp_data/scale.jpg", image)


# ========== ç¤ºä¾‹è°ƒç”¨ ==========
if __name__ == "__main__":
    #process_image(r'E:\G_data\ç•´åŒº\ç•´åŒº\02-æ•£å›¾\ç•´åŒºå…‰é•œæ•°æ®20x-2\20250107-26.jpg')
    process_image(r'D:\code\bl0116\big_data\cq_data\20x\image\20x-1.png')
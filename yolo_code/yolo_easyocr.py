import cv2
import numpy as np
from ultralytics import YOLO
import easyocr  # <--- 1. æ”¹ç”¨ EasyOCR
import re
import os
import json
import csv
from datetime import datetime
from pathlib import Path
import argparse

# ========== 1ï¸âƒ£ åŠ è½½æ¨¡å‹ ==========
# YOLO ç»§ç»­ç”¨ï¼Œå®ƒå·¥ä½œå¾—å¾ˆå®Œç¾
yolo_model = YOLO('./runs/detect/train/weights/best.pt') 

# åˆå§‹åŒ– EasyOCR (å¤ç”¨ PyTorch ç¯å¢ƒ)
# gpu=False: å¼ºåˆ¶ç”¨ CPUï¼Œç¨³å®šä¸”å¯¹å°å›¾è¶³å¤Ÿå¿«
reader = easyocr.Reader(['en'], gpu=False) 

# ========== 2ï¸âƒ£ YOLOæ£€æµ‹æ¯”ä¾‹å°º ==========
def detect_scale(image_path, conf_thresh=0.3): 
    image = cv2.imread(str(image_path))
    if image is None:
        print(f"âŒ å›¾åƒè·¯å¾„é”™è¯¯æˆ–æ— æ³•è¯»å–: {image_path}")
        return None, None, None, []

    results = yolo_model(image)[0]
    scale_bar_box = None
    scale_text_box = None
    detections = []

    print("\n--- YOLO æ£€æµ‹ç»“æœ ---")
    for box in results.boxes:
        cls_id = int(box.cls[0])
        conf = float(box.conf[0])
        label = results.names[cls_id]
        xyxy = box.xyxy[0].cpu().numpy().astype(int)
        print(f"ç±»åˆ«: {label}, ç½®ä¿¡åº¦: {conf:.2f}, åæ ‡: {xyxy}")
        
        if conf < conf_thresh:
            continue

        detections.append({
            "label": str(label),
            "conf": conf,
            # JSON å‹å¥½ï¼šè½¬æˆæ™®é€š list
            "xyxy": [int(v) for v in xyxy],
        })
        if label.lower() == "scale_bar":
            scale_bar_box = xyxy
        elif label.lower() == "scale_text":
            scale_text_box = xyxy

    # scale_*_box åŒæ ·è½¬æˆ list[int]
    if scale_bar_box is not None:
        scale_bar_box = [int(v) for v in scale_bar_box]
    if scale_text_box is not None:
        scale_text_box = [int(v) for v in scale_text_box]

    return image, scale_bar_box, scale_text_box, detections


def _default_output_dir() -> str:
    repo_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "."))
    out_dir = os.path.join(repo_root, "temp")
    os.makedirs(out_dir, exist_ok=True)
    return out_dir


def _ensure_dir(path: str) -> str:
    os.makedirs(path, exist_ok=True)
    return path


def _annotate_and_save(image, image_path: str, detections, scale_text: str | None = None, out_dir: str | None = None):
    if image is None:
        return None

    annotated = image.copy()

    for det in detections or []:
        label = det.get("label", "")
        conf = det.get("conf", 0.0)
        xyxy = det.get("xyxy", None)
        if xyxy is None or len(xyxy) != 4:
            continue

        x1, y1, x2, y2 = [int(v) for v in xyxy]
        color = (0, 255, 0) if label.lower() == "scale_bar" else (255, 0, 0)
        cv2.rectangle(annotated, (x1, y1), (x2, y2), color, 2)

        text = f"{label} {conf:.2f}".strip()
        if label.lower() == "scale_text" and scale_text:
            text = f"{text}: {scale_text}" if text else scale_text

        if text:
            y_text = max(0, y1 - 8)
            cv2.putText(
                annotated,
                text,
                (x1, y_text),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.6,
                color,
                2,
                lineType=cv2.LINE_AA,
            )

    out_dir = out_dir or _default_output_dir()
    annotated_dir = _ensure_dir(os.path.join(out_dir, "annotated"))
    stem = os.path.splitext(os.path.basename(image_path))[0]
    out_path = os.path.join(annotated_dir, f"{stem}_scale_bar.jpg")
    cv2.imwrite(out_path, annotated)
    print(f"âœ… æ ‡æ³¨ç»“æœå·²ä¿å­˜: {out_path}")
    return out_path

# ========== 3ï¸âƒ£ EasyOCR è¯†åˆ«æ¯”ä¾‹å°ºæ–‡å­— ==========
def recognize_scale_text(image, text_box):
    if text_box is None:
        print("âš ï¸ scale_text_box ä¸º Noneï¼Œæ— æ³• OCR")
        return None

    x1, y1, x2, y2 = text_box
    # å¢åŠ  padding é˜²æ­¢æ–‡å­—è´´è¾¹
    pad = 5
    h, w = image.shape[:2]
    x1 = max(0, x1 - pad)
    y1 = max(0, y1 - pad)
    x2 = min(w, x2 + pad)
    y2 = min(h, y2 + pad)

    crop = image[y1:y2, x1:x2]

    if crop.size == 0:
        print("âš ï¸ OCR è£å‰ªåŒºåŸŸä¸ºç©º")
        return None

    # å›¾åƒå¢å¼ºï¼šæ”¾å¤§ã€ç°åº¦ã€é˜ˆå€¼/è‡ªé€‚åº”é˜ˆå€¼ã€åç›¸ï¼Œå¤šè·¯å°è¯•æé«˜æ•°å­—è¯†åˆ«æˆåŠŸç‡
    crop_up = cv2.resize(crop, None, fx=4, fy=4, interpolation=cv2.INTER_CUBIC)
    gray = cv2.cvtColor(crop_up, cv2.COLOR_BGR2GRAY)
    gray = cv2.GaussianBlur(gray, (3, 3), 0)

    _, bin_otsu = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    bin_otsu_inv = cv2.bitwise_not(bin_otsu)
    bin_adapt = cv2.adaptiveThreshold(
        gray,
        255,
        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
        cv2.THRESH_BINARY,
        31,
        5,
    )
    bin_adapt_inv = cv2.bitwise_not(bin_adapt)

    variants = [
        ("bgr", crop_up),
        ("gray", gray),
        ("otsu", bin_otsu),
        ("otsu_inv", bin_otsu_inv),
        ("adapt", bin_adapt),
        ("adapt_inv", bin_adapt_inv),
    ]

    digits_allow = "0123456789.,"
    unit_allow = "Î¼Âµã›uUmMnN"
    full_allow = digits_allow + unit_allow + " "

    def _run_readtext(img, allow: str):
        try:
            return reader.readtext(img, allowlist=allow)
        except Exception as e:
            print(f"âŒ EasyOCR æŠ¥é”™({allow=}): {e}")
            return []

    def _pick_best(items, prefer_digits: bool):
        # items: list of (bbox, text, conf)
        best = None
        best_score = -1.0
        for (_bbox, txt, conf) in items or []:
            t = (txt or "").strip()
            if not t:
                continue
            digit_count = len(re.findall(r"\d", t))
            has_unit = bool(re.search(r"(?i)(nm|mm|Î¼m|um|Î¼|Âµ)", t))
            # prefer_digits æ—¶ï¼Œæ•°å­—æ•°é‡æƒé‡æ›´é«˜
            score = (digit_count * (50 if prefer_digits else 10)) + (5 if has_unit else 0) + float(conf)
            if score > best_score:
                best_score = score
                best = (t, float(conf), digit_count, has_unit)
        return best

    best_number = None  # (text, conf, digit_count, has_unit)
    best_unit = None
    best_full = None

    for name, img_var in variants:
        # 1) æ•°å­—ä¼˜å…ˆï¼šå°½é‡æŠ“åˆ° 1000 / 500 / 200 ç­‰
        r_num = _run_readtext(img_var, allow=digits_allow)
        if r_num:
            pick = _pick_best(r_num, prefer_digits=True)
            if pick and (best_number is None or pick[2] > best_number[2] or (pick[2] == best_number[2] and pick[1] > best_number[1])):
                best_number = pick

        # 2) å•ä½ä¼˜å…ˆï¼šæŠ“åˆ° Î¼m / nm / mm
        r_unit = _run_readtext(img_var, allow=unit_allow)
        if r_unit:
            pick = _pick_best(r_unit, prefer_digits=False)
            if pick and (best_unit is None or pick[1] > best_unit[1]):
                best_unit = pick

        # 3) å…¨é‡ï¼šå¤‡ç”¨ï¼ˆæ•°å­—+å•ä½ä¸€èµ·ï¼‰
        r_full = _run_readtext(img_var, allow=full_allow)
        if r_full:
            pick = _pick_best(r_full, prefer_digits=True)
            if pick and (best_full is None or pick[2] > best_full[2] or (pick[2] == best_full[2] and pick[1] > best_full[1])):
                best_full = pick

        if (best_full and best_full[2] >= 2) or (best_number and best_number[2] >= 2 and best_unit):
            # å·²ç»æœ‰è¾ƒå¯é çš„æ•°å­—äº†ï¼Œæå‰ç»“æŸ
            break

    # ç»„åˆç­–ç•¥ï¼šæœ‰æ•°å­— + æœ‰å•ä½åˆ™æ‹¼èµ·æ¥ï¼›å¦åˆ™é€€å› best_full æˆ– best_number
    chosen = None
    if best_number and best_unit:
        num_txt = best_number[0]
        unit_txt = best_unit[0]
        chosen = f"{num_txt}{unit_txt}"
        print(f"æœ€ç»ˆè¯†åˆ«æ–‡å­—(æ•°å­—+å•ä½ç»„åˆ): {chosen}")
        return chosen

    if best_full:
        chosen = best_full[0]
        print(f"æœ€ç»ˆè¯†åˆ«æ–‡å­—(å…¨é‡æœ€ä¼˜): {chosen}")
        return chosen

    if best_number:
        chosen = best_number[0]
        print(f"æœ€ç»ˆè¯†åˆ«æ–‡å­—(ä»…æ•°å­—): {chosen}")
        return chosen

    print("âš ï¸ OCR æœªè¯†åˆ«åˆ°æœ‰æ•ˆæ–‡å­—")
    return None

# ========== 4ï¸âƒ£ è§£ææ•°å€¼å’Œå•ä½ ==========
def parse_scale_text(text):
    if not text:
        return None, None

    raw = str(text).strip()

    # å½’ä¸€åŒ–ï¼šå¤„ç†å¤šç§å¾®ç±³å†™æ³•ã€ç©ºæ ¼ã€é€—å·ã€å¸¸è§è¯¯è¯†åˆ«
    s = raw
    s = s.replace("Âµ", "Î¼")
    s = s.replace("ã›", "Î¼m")
    s = s.replace("rn", "m")
    # å»æ‰å¸¸è§åˆ†éš”ç¬¦ï¼ˆOCR å¯èƒ½è¾“å‡º 1,000 æˆ– 1ï¼Œ000ï¼‰
    s = s.replace(",", "").replace("ï¼Œ", "")
    # æŠŠ 'um' / 'u m' ç»Ÿä¸€æˆ 'Î¼m'
    s = re.sub(r"(?i)u\s*m", "Î¼m", s)
    # å»æ‰å¤šä½™ç©ºç™½
    s = re.sub(r"\s+", "", s)

    # å¦‚æœåªæœ‰æ•°å­—ï¼ˆå«å°æ•°ï¼‰ï¼Œé»˜è®¤å•ä½ Î¼m
    if re.fullmatch(r"\d+(?:\.\d+)?", s):
        s = f"{s}Î¼m"

    print(f"è§£ææ¯”ä¾‹å°ºåŸå§‹æ–‡å­—: {raw} -> {s}")

    # æå–ï¼šæ•°å€¼ + å•ä½ï¼ˆæ”¯æŒ nm / Î¼m / mm / umï¼‰
    m = re.search(r"(?P<value>\d+(?:\.\d+)?)\s*(?P<unit>nm|mm|Î¼m|um)?", s, flags=re.IGNORECASE)
    if not m:
        print(f"âŒ æ— æ³•è§£ææ–‡å­—ä¸ºæ•°å€¼å•ä½: {raw}")
        return None, None

    value_str = m.group("value")
    unit_str = m.group("unit") or "Î¼m"

    try:
        value = float(value_str)
    except Exception:
        print(f"âŒ æ•°å€¼è½¬æ¢å¤±è´¥: {value_str} (raw={raw})")
        return None, None

    unit_lower = unit_str.lower()
    if unit_lower == "nm":
        unit = "nm"
    elif unit_lower == "mm":
        unit = "mm"
    else:
        # åŒ…æ‹¬ Î¼m / um
        unit = "Î¼m"

    print(f"âœ… è§£æç»“æœ: æ•°å€¼={value}, å•ä½={unit}")
    return value, unit

# ========== 5ï¸âƒ£ è®¡ç®—æ¯”ä¾‹ï¼ˆÎ¼m/pixelï¼‰ ==========
def compute_scale_ratio(scale_bar_box, scale_value):
    if scale_bar_box is None or scale_value is None:
        return None, None
    x1, y1, x2, y2 = scale_bar_box
    # è®¡ç®—åƒç´ é•¿åº¦
    pixel_length = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)
    if pixel_length == 0: return None, None
    
    ratio = scale_value / pixel_length
    return ratio, pixel_length

# ========== 6ï¸âƒ£ ä¸»æµç¨‹ ==========
def process_image(image_path):
    image, scale_bar_box, scale_text_box, detections = detect_scale(image_path)
    if image is None: return

    # å¦‚æœæ£€æµ‹åˆ°äº†æ–‡å­—æ¡†ï¼Œå°±å»è¯†åˆ«
    scale_value = None
    unit = "Î¼m"
    
    if scale_text_box is not None:
        text = recognize_scale_text(image, scale_text_box)
        scale_value, unit = parse_scale_text(text)
    
    if scale_value is None:
        print("âŒ æ— æ³•è·å–æ¯”ä¾‹å°ºæ•°å€¼")
        return

    ratio, pixel_length = compute_scale_ratio(scale_bar_box, scale_value)
    if ratio is None:
        print("âŒ æœªæ£€æµ‹åˆ°æ¯”ä¾‹å°ºæ¡")
        return

    print(f"\n=== ğŸ‰ æœ€ç»ˆç»“æœ ğŸ‰ ===")
    print(f"ç‰©ç†æ•°å€¼: {scale_value} {unit}")
    print(f"æ¡é•¿åº¦:   {pixel_length:.2f} pixels")
    print(f"åƒç´ æ¯”ä¾‹: {ratio:.6f} {unit}/pixel")

    # åœ¨åŸå›¾ä¸Šç”»å‡ºè¯†åˆ«å‡ºçš„æ£€æµ‹æ¡†ï¼Œå¹¶ä¿å­˜åˆ° ./temp
    ocr_text_for_label = None
    if scale_value is not None:
        ocr_text_for_label = f"{scale_value}{unit}"
    _annotate_and_save(image, image_path, detections, scale_text=ocr_text_for_label)


def _is_image_file(path: Path, exts: set[str]) -> bool:
    return path.is_file() and path.suffix.lower() in exts


def process_folder(
    input_dir: str,
    out_dir: str | None = None,
    conf_thresh: float = 0.3,
    recursive: bool = False,
    write_csv: bool = True,
):
    in_dir = Path(input_dir)
    if not in_dir.exists() or not in_dir.is_dir():
        raise FileNotFoundError(f"è¾“å…¥æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {input_dir}")

    out_dir = out_dir or _default_output_dir()
    _ensure_dir(out_dir)

    exts = {".jpg", ".jpeg", ".png", ".bmp", ".tif", ".tiff"}
    iterator = in_dir.rglob("*") if recursive else in_dir.glob("*")
    image_paths = [p for p in iterator if _is_image_file(p, exts)]
    image_paths.sort()

    results_json_path = os.path.join(out_dir, "results.json")
    results_csv_path = os.path.join(out_dir, "results.csv")

    all_rows: list[dict] = []
    print(f"\n=== æ‰¹é‡å¤„ç†å¼€å§‹ ===")
    print(f"è¾“å…¥æ–‡ä»¶å¤¹: {in_dir}")
    print(f"å›¾ç‰‡æ•°é‡:   {len(image_paths)}")
    print(f"è¾“å‡ºç›®å½•:   {out_dir}")

    for idx, img_path in enumerate(image_paths, start=1):
        print(f"\n[{idx}/{len(image_paths)}] å¤„ç†: {img_path}")
        row: dict = {
            "image": str(img_path),
            "annotated_image": None,
            "scale_value": None,
            "unit": None,
            "pixel_length": None,
            "ratio": None,
            "detections": [],
            "error": None,
        }

        try:
            image, scale_bar_box, scale_text_box, detections = detect_scale(str(img_path), conf_thresh=conf_thresh)
            row["detections"] = detections

            if image is None:
                row["error"] = "image_read_failed"
                all_rows.append(row)
                continue

            scale_value = None
            unit = "Î¼m"
            ocr_text_for_label = None

            if scale_text_box is not None:
                text = recognize_scale_text(image, scale_text_box)
                scale_value, unit = parse_scale_text(text)

            if scale_value is None:
                row["error"] = "scale_text_parse_failed"
                # ä¾ç„¶æŠŠæ£€æµ‹æ¡†ç”»å‡ºæ¥ï¼Œæ–¹ä¾¿æ’æŸ¥
                row["annotated_image"] = _annotate_and_save(image, str(img_path), detections, scale_text=None, out_dir=out_dir)
                all_rows.append(row)
                continue

            ratio, pixel_length = compute_scale_ratio(scale_bar_box, scale_value)
            if ratio is None:
                row["error"] = "scale_bar_not_found"
                row["annotated_image"] = _annotate_and_save(image, str(img_path), detections, scale_text=f"{scale_value}{unit}", out_dir=out_dir)
                all_rows.append(row)
                continue

            row["scale_value"] = float(scale_value)
            row["unit"] = unit
            row["pixel_length"] = float(pixel_length) if pixel_length is not None else None
            row["ratio"] = float(ratio)

            ocr_text_for_label = f"{scale_value}{unit}"
            row["annotated_image"] = _annotate_and_save(image, str(img_path), detections, scale_text=ocr_text_for_label, out_dir=out_dir)

        except Exception as e:
            row["error"] = f"exception: {type(e).__name__}: {e}"

        all_rows.append(row)

    payload = {
        "created_at": datetime.now().isoformat(timespec="seconds"),
        "input_dir": str(in_dir),
        "out_dir": str(out_dir),
        "count": len(all_rows),
        "results": all_rows,
    }
    with open(results_json_path, "w", encoding="utf-8") as f:
        json.dump(payload, f, ensure_ascii=False, indent=2)

    if write_csv:
        with open(results_csv_path, "w", newline="", encoding="utf-8") as f:
            writer = csv.DictWriter(
                f,
                fieldnames=[
                    "image",
                    "annotated_image",
                    "scale_value",
                    "unit",
                    "pixel_length",
                    "ratio",
                    "error",
                ],
            )
            writer.writeheader()
            for r in all_rows:
                writer.writerow({k: r.get(k) for k in writer.fieldnames})

    print("\n=== æ‰¹é‡å¤„ç†å®Œæˆ ===")
    print(f"ç»“æœJSON: {results_json_path}")
    if write_csv:
        print(f"ç»“æœCSV:  {results_csv_path}")


def _build_arg_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(description="YOLO + EasyOCR æ‰¹é‡è¯†åˆ«æ¯”ä¾‹å°ºå¹¶ä¿å­˜æ ‡æ³¨ç»“æœ")
    parser.add_argument("--input_dir", type=str, required=True, help="å¾…å¤„ç†å›¾ç‰‡æ–‡ä»¶å¤¹")
    parser.add_argument("--out_dir", type=str, default=None, help="è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: yolo_code/tempï¼‰")
    parser.add_argument("--conf", type=float, default=0.3, help="YOLO ç½®ä¿¡åº¦é˜ˆå€¼")
    parser.add_argument("--recursive", action="store_true", help="é€’å½’éå†å­ç›®å½•")
    parser.add_argument("--no_csv", action="store_true", help="ä¸è¾“å‡º results.csvï¼Œä»…è¾“å‡º results.json")
    return parser

if __name__ == "__main__":
    parser = _build_arg_parser()
    args = parser.parse_args()
    process_folder(
        input_dir=args.input_dir,
        out_dir=args.out_dir,
        conf_thresh=args.conf,
        recursive=args.recursive,
        write_csv=not args.no_csv,
    )
from unittest import result
import cv2
import numpy as np
from ultralytics import YOLO
import easyocr  # <--- 1. æ”¹ç”¨ EasyOCR
import re
import os

# ========== 1ï¸âƒ£ åŠ è½½æ¨¡å‹ ==========
# YOLO ç»§ç»­ç”¨ï¼Œå®ƒå·¥ä½œå¾—å¾ˆå®Œç¾
yolo_model = YOLO('./runs/detect/train/weights/best.pt') 

# åˆå§‹åŒ– EasyOCR (å¤ç”¨ PyTorch ç¯å¢ƒ)
# gpu=False: å¼ºåˆ¶ç”¨ CPUï¼Œç¨³å®šä¸”å¯¹å°å›¾è¶³å¤Ÿå¿«
reader = easyocr.Reader(['en'], gpu=False) 

# ========== 2ï¸âƒ£ YOLOæ£€æµ‹æ¯”ä¾‹å°º ==========
def detect_scale(image_path, conf_thresh=0.3): 
    image = cv2.imread(image_path)
    if image is None:
        print(f"âŒ å›¾åƒè·¯å¾„é”™è¯¯æˆ–æ— æ³•è¯»å–: {image_path}")
        return None, None, None, []

    results = yolo_model(image)[0]
    scale_bar_box = None
    scale_text_box = None
    detections = []

    print("\n--- YOLO æ£€æµ‹ç»“æœ ---")
    for box in results.boxes:
        cls_id = int(box.cls[0])
        conf = float(box.conf[0])
        label = results.names[cls_id]
        xyxy = box.xyxy[0].cpu().numpy().astype(int)
        print(f"ç±»åˆ«: {label}, ç½®ä¿¡åº¦: {conf:.2f}, åæ ‡: {xyxy}")
        
        if conf < conf_thresh:
            continue

        detections.append({
            "label": str(label),
            "conf": conf,
            "xyxy": xyxy,
        })
        if label.lower() == "scale_bar":
            scale_bar_box = xyxy
        elif label.lower() == "scale_text":
            scale_text_box = xyxy

    return image, scale_bar_box, scale_text_box, detections


def _ensure_output_dir() -> str:
    repo_root = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
    out_dir = os.path.join(repo_root, "temp")
    os.makedirs(out_dir, exist_ok=True)
    return out_dir


def _annotate_and_save(image, image_path: str, detections, scale_text: str | None = None):
    if image is None:
        return None

    annotated = image.copy()

    for det in detections or []:
        label = det.get("label", "")
        conf = det.get("conf", 0.0)
        xyxy = det.get("xyxy", None)
        if xyxy is None or len(xyxy) != 4:
            continue

        x1, y1, x2, y2 = [int(v) for v in xyxy]
        color = (0, 255, 0) if label.lower() == "scale_bar" else (255, 0, 0)
        cv2.rectangle(annotated, (x1, y1), (x2, y2), color, 2)

        text = f"{label} {conf:.2f}".strip()
        if label.lower() == "scale_text" and scale_text:
            text = f"{text}: {scale_text}" if text else scale_text

        if text:
            y_text = max(0, y1 - 8)
            cv2.putText(
                annotated,
                text,
                (x1, y_text),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.6,
                color,
                2,
                lineType=cv2.LINE_AA,
            )

    out_dir = _ensure_output_dir()
    stem = os.path.splitext(os.path.basename(image_path))[0]
    out_path = os.path.join(out_dir, f"{stem}_annotated.jpg")
    cv2.imwrite(out_path, annotated)
    print(f"âœ… æ ‡æ³¨ç»“æœå·²ä¿å­˜: {out_path}")
    return out_path

# ========== 3ï¸âƒ£ EasyOCR è¯†åˆ«æ¯”ä¾‹å°ºæ–‡å­— ==========
def recognize_scale_text(image, text_box):
    if text_box is None:
        print("âš ï¸ scale_text_box ä¸º Noneï¼Œæ— æ³• OCR")
        return None

    x1, y1, x2, y2 = text_box
    # å¢åŠ  padding é˜²æ­¢æ–‡å­—è´´è¾¹
    pad = 5
    h, w = image.shape[:2]
    x1 = max(0, x1 - pad)
    y1 = max(0, y1 - pad)
    x2 = min(w, x2 + pad)
    y2 = min(h, y2 + pad)

    crop = image[y1:y2, x1:x2]
    
    # å›¾åƒå¢å¼ºï¼šæ”¾å¤§2å€ï¼ŒäºŒå€¼åŒ– (è¿™å¯¹ EasyOCR ä¹Ÿå¾ˆé‡è¦)
    crop = cv2.resize(crop, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)
    gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)
    _, crop_bin = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    
    # EasyOCR å¯ä»¥ç›´æ¥åƒ numpy æ•°ç»„
    try:
        # allowlist: åªå…è®¸è¯†åˆ«æ•°å­—å’Œå¸¸è§å•ä½å­—æ¯ï¼Œæ’é™¤å¹²æ‰°
        result = reader.readtext(crop_bin, allowlist='0123456789umNMnm. ')
    except Exception as e:
        print(f"âŒ EasyOCR æŠ¥é”™: {e}")
        return None

    if not result:
        print("âš ï¸ OCR æœªè¯†åˆ«åˆ°æ–‡å­—")
        return None

    print(f"EasyOCR åŸå§‹ç»“æœ: {result}")
    
    # EasyOCR è¿”å›æ ¼å¼: [([[x,y]..], 'text', conf), ...]
    # æˆ‘ä»¬å–ç½®ä¿¡åº¦æœ€é«˜çš„ä¸€ä¸ª
    best_result = sorted(result, key=lambda x: x[2], reverse=True)[0]
    text = best_result[1].strip()
    print("æœ€ç»ˆè¯†åˆ«æ–‡å­—:", text)

    return text

# ========== 4ï¸âƒ£ è§£ææ•°å€¼å’Œå•ä½ ==========
def parse_scale_text(text):
    if not text: return None, None
    
    # è‡ªåŠ¨ä¿®æ­£è§„åˆ™
    text = text.replace("u", "Î¼").replace("Âµ", "Î¼").replace("rn", "m")
    
    # å¦‚æœåªæœ‰æ•°å­—ï¼Œå¼ºåˆ¶è¡¥ Î¼m
    if re.fullmatch(r"[\d\.]+", text):
        text += "Î¼m"
        
    print(f"è§£ææ¯”ä¾‹å°ºåŸå§‹æ–‡å­—: {text}")

    # æå–æ•°å€¼å’Œå•ä½
    match = re.search(r"([\d\.]+)\s*([a-zA-ZÎ¼]+)?", text)
    if match:
        value = float(match.group(1))
        unit = match.group(2) if match.group(2) else "Î¼m"
        # ç»Ÿä¸€å•ä½å†™æ³•
        if "nm" in unit.lower(): unit = "nm"
        elif "mm" in unit.lower(): unit = "mm"
        else: unit = "Î¼m"
            
        print(f"âœ… è§£æç»“æœ: æ•°å€¼={value}, å•ä½={unit}")
        return value, unit
    else:
        print(f"âŒ æ— æ³•è§£ææ–‡å­—ä¸ºæ•°å€¼å•ä½: {text}")
        return None, None

# ========== 5ï¸âƒ£ è®¡ç®—æ¯”ä¾‹ï¼ˆÎ¼m/pixelï¼‰ ==========
def compute_scale_ratio(scale_bar_box, scale_value):
    if scale_bar_box is None or scale_value is None:
        return None, None
    x1, y1, x2, y2 = scale_bar_box
    # è®¡ç®—åƒç´ é•¿åº¦
    pixel_length = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)
    if pixel_length == 0: return None, None
    
    ratio = scale_value / pixel_length
    return ratio, pixel_length

# ========== 6ï¸âƒ£ ä¸»æµç¨‹ ==========
def process_image(image_path):
    image, scale_bar_box, scale_text_box, detections = detect_scale(image_path)
    if image is None: return

    # å¦‚æœæ£€æµ‹åˆ°äº†æ–‡å­—æ¡†ï¼Œå°±å»è¯†åˆ«
    scale_value = None
    unit = "Î¼m"
    
    if scale_text_box is not None:
        text = recognize_scale_text(image, scale_text_box)
        scale_value, unit = parse_scale_text(text)
    
    if scale_value is None:
        print("âŒ æ— æ³•è·å–æ¯”ä¾‹å°ºæ•°å€¼")
        return

    ratio, pixel_length = compute_scale_ratio(scale_bar_box, scale_value)
    if ratio is None:
        print("âŒ æœªæ£€æµ‹åˆ°æ¯”ä¾‹å°ºæ¡")
        return

    print(f"\n=== ğŸ‰ æœ€ç»ˆç»“æœ ğŸ‰ ===")
    print(f"ç‰©ç†æ•°å€¼: {scale_value} {unit}")
    print(f"æ¡é•¿åº¦:   {pixel_length:.2f} pixels")
    print(f"åƒç´ æ¯”ä¾‹: {ratio:.6f} {unit}/pixel")

    # åœ¨åŸå›¾ä¸Šç”»å‡ºè¯†åˆ«å‡ºçš„æ£€æµ‹æ¡†ï¼Œå¹¶ä¿å­˜åˆ° ./temp
    ocr_text_for_label = None
    if scale_value is not None:
        ocr_text_for_label = f"{scale_value}{unit}"
    _annotate_and_save(image, image_path, detections, scale_text=ocr_text_for_label)

if __name__ == "__main__":
    process_image(r'D:\code\bl0116\big_data\cq_data\20x\image\20x-1.png')